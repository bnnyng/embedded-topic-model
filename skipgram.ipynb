{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Preliminaries"
      ],
      "metadata": {
        "id": "0aOj3W6S2kSA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DronGAU4yXnG",
        "outputId": "2c0593c8-6212-4cb1-90e1-6e6717d490a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.14.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tqdm\n",
        "\n",
        "import gensim\n",
        "from gensim.models import Word2Vec, Phrases"
      ],
      "metadata": {
        "id": "Ni3_MmoB2n1q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import data"
      ],
      "metadata": {
        "id": "ohTvTlof2uXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CORPUS_COL = 'content-cleaned'\n",
        "VOCAB_COL = 'content-no-top'\n",
        "# Maybe use bi-grams?"
      ],
      "metadata": {
        "id": "9yxIOuPXBCjo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_json('comments-semantic-processed.json')\n",
        "df[CORPUS_COL] = df[CORPUS_COL].str.split()\n",
        "documents = df[CORPUS_COL].tolist()\n",
        "len(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkhSYKEF2vfq",
        "outputId": "52a29265-be0c-48f0-8d26-5f3e7f669a0f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15924"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding model"
      ],
      "metadata": {
        "id": "ZV-qOn8k2mN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and save model\n",
        "bigram_transformer = Phrases(documents)\n",
        "model_embedding = Word2Vec(\n",
        "    sentences=documents,\n",
        "    vector_size=300,\n",
        "    window=3,\n",
        "    min_count=10,\n",
        "    workers=4,\n",
        "    sg=1\n",
        ")\n",
        "model_embedding.save('test-Word2Vec-all.model')"
      ],
      "metadata": {
        "id": "nvfF8iNm2bj1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save embedding matrix for vocab\n",
        "project_ids = df['project-id'].unique().tolist()\n",
        "corpus_keys = model_embedding.wv.key_to_index.keys()\n",
        "\n",
        "for id in project_ids:\n",
        "    print(f'Creating embedding matrix for {id}...')\n",
        "    count = 0\n",
        "    df_project = df[df['project-id'] == id]\n",
        "    vocabulary = list(set(df_project[VOCAB_COL].str.cat(sep=' ').split()))\n",
        "    f = open(f'test-embedMatrix-{id}.txt', 'w')\n",
        "    for v in corpus_keys:\n",
        "        if v in vocabulary:\n",
        "            vec = model_embedding.wv[v]\n",
        "            vec_str = ['%.9f' % val for val in vec]\n",
        "            vec_str = ' '.join(vec_str)\n",
        "            f.write(v + ' ' + vec_str + '\\n')\n",
        "            count += 1\n",
        "    f.close()\n",
        "    print(f'Embedding matrix created for {count} words in {id}.\\n')\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvePUYed-KcQ",
        "outputId": "d5728a57-e2f3-42b7-8fcc-3373752c1b13"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating embedding matrix for P1...\n",
            "Embedding matrix created for 2921 words in P1.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}